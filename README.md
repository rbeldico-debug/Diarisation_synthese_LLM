# üåä Oc√©ane - Assistant de R√©flexion S√©mantique (v2.5)

Oc√©ane est un √©cosyst√®me multi-agents local con√ßu pour transformer vos r√©flexions orales en un **Zettelkasten** structur√©.
Cette version introduit une **Architecture Cognitive Hybride** : le syst√®me poss√®de une "m√©moire de travail" volatile (RAM) qui simule l'attention, et une "m√©moire √† long terme" persistante (Obsidian)

## üèóÔ∏è Architecture des Agents
1.  **P1: L'Oreille** (Silero VAD) : D√©coupe le flux audio en segments logiques.
2.  **P2: Le Cerveau** (Whisper + Semantic Router) : Transcrit et identifie les intentions via **Similarit√© Cosinus**.
3.  **P3: La Bouche** (Edge-TTS) : Restitue des briefings vocaux (Voix: Vivienne).
4.  **P4: L'Analyste** (Moteur Cognitif) :
    *   G√®re le **Graphe Mental** en RAM (Poids, Activation, Ignition).
    *   Ex√©cute la **Propagation Top-Down** (l'activation d'un concept r√©veille ses voisins).
    *   Interroge le **LLM (Mistral/GPT)** pour la synth√®se et l'extraction de concepts.
5.  **P5: Le Moniteur** (FastAPI Sidecar) : Un serveur Web d√©di√© qui affiche l'√©tat interne du cerveau en temps r√©el.

## üß† Fonctions Cognitives (Nouveau)
*   **Dynamique d'Attention (ADR-022)** : Chaque note poss√®de une "Barre de Vie" (Activation).
    *   **Ignition üî•** : Si l'attention d√©passe un seuil, la note devient "Consciente" et est envoy√©e au LLM.
    *   **Fatigue üìâ** : Si une note reste active trop longtemps, une p√©nalit√© la force √† s'√©teindre pour laisser place √† d'autres sujets.
*   **Propagation Neuronale** : Parler de "Politique" activera doucement les notes li√©es comme "√âthique" ou "Pouvoir" (Top-Down).
*   **Observabilit√© Totale (ADR-023)** : Un Dashboard Web (Port 8003) permet de voir :
    *   L'activit√© neuronale (Jauges d'activation).
    *   Les Prompts bruts envoy√©s au LLM et ses r√©ponses exactes (Debug).

## üõ†Ô∏è Maintenance & Commandes

**Lancement** : Ne lancez plus `python main.py` manuellement. Utilisez le script qui g√®re le nettoyage des processus et le lancement simultan√© du serveur Web et du moteur.
1.  Double-cliquez sur **`start_oceane.bat`**.
2.  Deux fen√™tres s'ouvrent :
    *   **Le Moteur** : Affiche les logs techniques.
    *   **Le Serveur Web** : D√©marre en arri√®re-plan.
3.  Ouvrez votre navigateur sur : **[http://localhost:8003](http://localhost:8003)** (ou 8002 selon config).

**Arr√™t propre** : `python stop.py` (D√©clenche l'archivage final et coupe les processus).

## üìä Architecture du Flux

```mermaid
graph TD
    subgraph "H√îTE WINDOWS (Python 3.11)"
        A[Microphone] --> B(P1: Oreille)
        B -->|Audio| C(P2: Cerveau)
        C -->|Intent + Texte| D[(Bus de Donn√©es JSONL)]
        
        subgraph "MOTEUR COGNITIF"
            D --> E(P4: Analyste)
            E <-->|R/W| F[M√©moire RAM GraphState]
            F -->|Sauvegarde| G[Obsidian Vault .md]
            E -->|Snapshot Activit√©| H[brain_activity.json]
        end
        
        subgraph "MONITORING (Sidecar)"
            D --> I(P5: Serveur Web FastAPI)
            H --> I
            I -->|WebSocket/Polling| J[Navigateur Web Dashboard]
        end
        
        C -->|TTS| K(P3: Bouche)
    end

    subgraph "DOCKER & OLLAMA"
        C -.->|API| Whisper
        E -.->|API| LLM_Ollama
    end
```

## üõ†Ô∏è Pr√©-requis

*   **OS** : Windows 10/11.
*   **Outils** : Docker Desktop, Ollama.
*   **Python** : 3.11 avec environnement virtuel (Attention, 3.13 ne fonctionne pas).

## üöÄ Installation Rapide

1.  **Pr√©parer l'environnement Python** :
    ```bash
    python -m venv .venv
    .venv\Scripts\activate
    pip install -r requirements.txt
    ```

2.  **Lancer le moteur IA (Docker)** :
    *   Remplissez votre `HF_TOKEN` dans le fichier `docker-compose.yml`.
    *   Dans un terminal, lancez :
    ```bash
    docker compose up -d
    ```

3.  **V√©rifier le serveur** :
    Acc√©dez √† [http://localhost:8000/docs](http://localhost:8000/docs). Si la page s'affiche, le moteur est pr√™t.

## ‚öôÔ∏è Configuration

*   **Diarisation** : Automatiquement g√©r√©e par le serveur Speaches via l'argument `extra_body={"diarization": True}` dans `diarization.py`.
*   **VRAM** : Le mod√®le `large-v3` consomme environ 5-6 Go de VRAM sur votre GPU via Docker.
*   **Param√®tres cognitifs** : Ajustables pour changer la "personnalit√©" du syst√®me.

## ‚ñ∂Ô∏è Utilisation

1.  Lancer Ollama.
2.  Lancer le conteneur Docker (si pas d√©j√† fait).
3.  Double-cliquez sur start_oceane.bat. Deux fen√™tres s'ouvrent :
   - Le Moteur : Affiche les logs techniques.
   - Le Serveur Web : D√©marre en arri√®re-plan.
   Ouvrez votre navigateur sur : http://localhost:8002 (ou 8002 selon config).


---

### Rappel du fichier `docker-compose.yml` (√Ä placer √† la racine)
C'est le fichier qui "sauve" ton projet.

```yaml
name: Diarisation_Synthese_LLM

services:
  # --- MOTEUR AUDIO (Whisper) ---
  whisper:
    image: ghcr.io/speaches-ai/speaches:latest-cuda
    container_name: whisper-server
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - whisper_data:/home/ubuntu/.cache/huggingface
    environment:
      - HF_TOKEN=[CLE API ICI]
      - HF_HOME=/home/ubuntu/.cache/huggingface
      - SPEACHES_MODELS_PRELOAD=Systran/faster-whisper-large-v3
      - WHISPER__MODEL=Systran/faster-whisper-large-v3
      - WHISPER__DEVICE=cuda
      - WHISPER__COMPUTE_TYPE=int8_float16
      - WHISPER__NUM_WORKERS=4
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # --- LE CERVEAU UNIQUE (Ollama: Nemo + Embeddings) ---
  router-llm:
    image: ollama/ollama:latest
    container_name: LLM-router
    restart: unless-stopped
    ports:
      - "11435:11434"
    volumes:
      - ollama_storage:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # --- LA M√âMOIRE VECTORIELLE (ChromaDB) ---
  chromadb:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chromadb-server
    restart: unless-stopped
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma # Volume persistant pour le RAG
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE

volumes:
  whisper_data:
  ollama_storage:
  chroma_data:
```
