# üß† Local AI Voice Assistant (LAVA)

Un assistant vocal enti√®rement local, modulaire et respectueux de la vie priv√©e.
Il combine reconnaissance vocale (Whisper), identification des locuteurs (Pyannote) et intelligence conversationnelle (LLM via Ollama), le tout orchestr√© en Python via multiprocessing.

## üìä Architecture du Flux de Donn√©es

Le syst√®me suit une architecture **Producer-Consumer** pour garantir qu'aucune donn√©e audio n'est perdue pendant que l'IA r√©fl√©chit.

```mermaid
graph TD
    subgraph "PROCESS 1 : L'OREILLE (Producer)"
        A[Microphone] -->|Flux Continu| B(VAD Engine\nSilero)
        B -->|Analyse Ms par Ms| C{Silence > 1s ?}
        C -- Non --> B
        C -- Oui --> D[Cr√©ation AudioPayload]
    end

    D -->|Queue - Multiprocessing| E

    subgraph "PROCESS 2 : LE CERVEAU (Consumer)"
        E[R√©ception Segment] --> F[Transcriber\nFaster-Whisper]
        E --> G[Diarizer\nPyannote 3.1]
        
        F -->|Texte| H[Formatter\nMemoire Glissante]
        G -->|Speaker ID| H
        
        H -->|Contexte Conversation| I[LLM Client\nOllama / GPT-OSS]
        I -->|R√©ponse G√©n√©r√©e| J[Sortie Console]
    end
```

## üõ†Ô∏è Pr√©-requis Techniques

*   **OS** : Windows 10/11 (Recommand√© avec GPU NVIDIA)
*   **Python** : Version **3.10** √† **3.12** (3.13 non support√© par PyTorch actuellement)
*   **GPU** : NVIDIA avec 8GB+ VRAM recommand√©s (Test√© sur RTX 4060 Ti 16GB)
*   **Outils Externes** : 
    *   [Ollama](https://ollama.com/) install√© et tournant en t√¢che de fond.

## üöÄ Installation (Windows / NVIDIA)

L'installation de PyTorch avec support CUDA est d√©licate. Suivez cet ordre pr√©cis :

1.  **Cr√©er un environnement virtuel** :
    ```bash
    python -m venv .venv
    .venv\Scripts\activate
    ```

2.  **Installer le socle PyTorch (CRITIQUE)** :
    *Ceci garantit l'utilisation du GPU. Ne sautez pas cette √©tape.*
    ```bash
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    ```

3.  **Installer les biblioth√®ques NVIDIA (Correctif DLL)** :
    ```bash
    pip install nvidia-cudnn-cu12 nvidia-cublas-cu12
    ```

4.  **Installer le reste des d√©pendances** :
    ```bash
    pip install -r requirements.txt
    ```

5.  **Configuration** :
    *   Dupliquez le fichier `.env.example` en `.env`.
    *   Ajoutez votre token Hugging Face (n√©cessaire pour Pyannote) : `HF_TOKEN=hf_...`
    *   Acceptez les conditions d'utilisation de [Pyannote Segmentation](https://huggingface.co/pyannote/segmentation-3.0) et [Speaker Diarization](https://huggingface.co/pyannote/speaker-diarization-3.1) sur Hugging Face.

## ‚öôÔ∏è Configuration (`config.py`)

Vous pouvez ajuster le comportement de l'assistant dans `config.py` :
*   `VAD_MIN_SILENCE_DURATION_MS` : Ajuste la "patience" de l'√©coute (d√©faut : 1000ms).
*   `SPEAKER_MAPPING` : Renomme `SPEAKER_00` en "Utilisateur" ou "G√©rald".
*   `LLM_MODEL_NAME` : Change le mod√®le utilis√© par Ollama (ex: `mistral`, `llama3`, `gpt-oss:20b`).

## ‚ñ∂Ô∏è Utilisation

1.  Assurez-vous qu'Ollama est lanc√© : `ollama serve`
2.  Lancez le programme principal :
    ```bash
    python main.py
    ```
3.  Parlez dans le micro. Appuyez sur `Ctrl+C` pour arr√™ter.

## üß™ Tests Unitaires

*   `test_step_1.py` : Teste uniquement le micro et la d√©tection de voix (VAD). Sauvegarde les wav dans `test_segments/`.
*   `test_step_2.py` : Teste la cha√Æne IA (Whisper + Diarization) sur un fichier enregistr√©.
```