### üìÑ ADR-001 : Strat√©gie de Capture Audio Segment√©e par VAD Locale
*   **Statut** : R√©alis√©
*   **Contexte** : Pour traiter de l'audio en temps r√©el, il est inefficace d'envoyer un flux continu √† un serveur d'IA. Il faut segmenter l'audio en phrases logiques. Couper arbitrairement (ex: toutes les 5s) brise la coh√©rence s√©mantique.
*   **D√©cision** : Maintenir une **VAD (Voice Activity Detection)** l√©g√®re via Silero-VAD s'ex√©cutant sur l'h√¥te local (Processus "Oreille").
*   **Justification** : 
    1.  **R√©duction de Latence** : La d√©tection imm√©diate du silence (seuil `VAD_MIN_SILENCE_DURATION_MS`) permet de cl√¥turer le segment instantan√©ment.
    2.  **√âconomie de Bande Passante** : Seuls les segments contenant de la parole sont envoy√©s au serveur Docker. On √©vite de saturer l'API avec du bruit de fond ou du silence.
    3.  **Ind√©pendance** : La capture reste fluide m√™me si le r√©seau local ou le conteneur Docker subit une micro-latence.
*   **Cons√©quences** : 
    *   N√©cessite `torch` et `numpy` sur l'h√¥te Windows. 
    *   L'utilisation de `trust_repo=True` est requise pour le chargement de Silero via TorchHub.

---

### üìÑ ADR-002 : Inf√©rence D√©port√©e via Micro-service (Docker Speaches)
*   **Statut** : **Superpose et remplace** la version pr√©c√©dente orient√©e "Biblioth√®ques Locales". R√©alis√©e.
*   **Contexte** : L'installation locale de Faster-Whisper et Pyannote sous Windows est sujette aux conflits de d√©pendances (NumPy, CUDA DLLs). De plus, charger les mod√®les en m√©moire √† chaque ex√©cution cr√©e une latence inacceptable.
*   **D√©cision** : D√©porter l'intelligence lourde (Transcription & Diarisation) dans un conteneur Docker utilisant **Speaches** (bas√© sur Faster-Whisper et FastAPI).
*   **Configuration technique** :
    1.  **Mod√®le** : `Systran/faster-whisper-large-v3` pr√©-charg√© en VRAM.
    2.  **Protocole** : API REST compatible OpenAI.
    3.  **Diarisation** : Activ√©e via l'argument `response_format="verbose_json"` dans l'appel unique de transcription.
*   **Justification** : 
    1.  **Stabilit√©** : Environnement Linux isol√© (Docker), √©liminant les probl√®mes de drivers Windows.
    2.  **Performance** : Le mod√®le est "chaud" (d√©j√† charg√©), r√©duisant le Temps de Premier Mot (TTFT).
    3.  **Modularit√©** : Permet de mettre √† jour le moteur d'IA sans toucher au code de capture Python.
*   **Cons√©quences** : 
    *   D√©pendance √† Docker Desktop et NVIDIA Container Toolkit.
    *   N√©cessit√© de g√©rer les timeouts r√©seau entre l'h√¥te et le conteneur.

---

### üìÑ ADR-003 : Architecture Multi-Processus et Orchestration Asynchrone
*   **Statut** : R√©alis√©
*   **Contexte** : La capture audio est une t√¢che critique en temps r√©el qui ne doit subir aucun ralentissement li√© aux appels r√©seau (API) ou au traitement LLM.
*   **D√©cision** : Architecture **Producteur/Consommateur** utilisant `multiprocessing`.
    *   **P1 (Oreille)** : Producteur pur. Capture + VAD. Priorit√© haute.
    *   **P2 (Cerveau)** : Orchestrateur I/O Bound. Consomme la file d'attente, appelle l'API Docker, g√®re l'historique de conversation et interroge le LLM (Ollama).
*   **Justification** : 
    1.  **Parall√©lisme** : L'utilisation de processus (plut√¥t que de threads) contourne le GIL Python, garantissant que la capture audio reste fluide m√™me pendant une r√©ponse LLM complexe.
    2.  **R√©silience** : Si le processus Cerveau plante, le processus Oreille peut √™tre maintenu en vie ou red√©marr√© proprement.
*   **Cons√©quences** : 
    *   Communication via `multiprocessing.Queue` limitant le partage d'objets complexes (s√©rialisation n√©cessaire).
    *   Complexit√© accrue pour la terminaison propre du signal (n√©cessite un `Event` de stop).
