### üìÑ ADR-007 : Routage d'Intention et Double Latence (Reflex vs. Thought)
*   **R√©f√©rence** : Concernant la r√©activit√© et la pertinence des interventions de l'IA.
*   **Contexte** : Actuellement, chaque phrase d√©tect√©e par la VAD d√©clenche une r√©ponse du LLM. Cela cr√©e des interruptions inutiles lors de r√©flexions √† haute voix ou de prises de notes.
*   **D√©cision** : Introduire un **Agent Routeur** utilisant un mod√®le ultra-l√©ger (ex: `Llama-3.2-1B` ou `Phi-3.5-mini`) dont l'unique r√¥le est de classer le segment audio en : `[IGNORE]`, `[ACQUIESCE]` (ex: "D'accord", "Je note"), ou `[REPONDRE]`.
*   **Justification** :
    1.  **√âconomie Cognitive** : L'IA ne parle que si elle apporte une valeur imm√©diate ou si elle est sollicit√©e.
    2.  **Performance** : Ces mod√®les tournent en local avec une latence < 150ms, pr√©servant la fluidit√©.
*   **Strat√©gie d'impl√©mentation** :
    *   Le `brain_process` appelle d'abord le Routeur avec un prompt syst√®me minimaliste : *"R√©ponds uniquement par un mot-cl√©. L'utilisateur est-il en train de r√©fl√©chir seul ou te pose-t-il une question ?"*.
    *   Si `[IGNORE]`, le texte est envoy√© au stockage (ADR-008) mais la file TTS reste vide.
*   **Impact** : R√©duction drastique du sentiment "d'oppression" de l'IA qui veut toujours avoir le dernier mot.

---

### üìÑ ADR-008 : Persistance Hybride (Source de V√©rit√© vs. Vue Utilisateur)
*   **R√©f√©rence** : Concernant la p√©rennit√© des donn√©es et l'interface sur second √©cran.
*   **Contexte** : Nous avons besoin d'une trace exploitable par l'IA (donn√©e brute) et d'une trace lisible par l'humain (synth√®se).
*   **D√©cision** : Adopter un stockage √† deux niveaux :
    1.  **JSON Lines (.jsonl)** : Chaque √©v√©nement (Transcription, Diarisation, R√©ponse IA, D√©cision Routeur) est enregistr√© comme une ligne JSON unique et immuable.
    2.  **Markdown Dynamique (.md)** : Un fichier de "Dashboard" r√©√©crit p√©riodiquement par l'Analyste (ADR-009).
*   **Justification** :
    1.  **Robustesse (JSONL)** : En cas de crash, seule la derni√®re ligne est perdue. Pas de corruption de fichier.
    2.  **Interop√©rabilit√©** : Le Markdown est imm√©diatement lisible sur ton 2√®me √©cran via n'importe quel √©diteur (Obsidian, VS Code).
*   **Strat√©gie d'impl√©mentation** :
    *   Cr√©ation d'une classe `MemoryManager` qui √©crit dans `journal.jsonl`.
    *   Chaque entr√©e JSON contient : `timestamp`, `source` (user/ai), `text`, `speaker_id`, et `intent_tag`.
*   **Impact** : S√©pare totalement la couche de donn√©es de la couche d'affichage.

---

### üìÑ ADR-009 : Agent Analyste Asynchrone (G√©n√©ration de Valeur)
*   **R√©f√©rence** : Concernant la transformation des donn√©es en connaissances organis√©es.
*   **Contexte** : La simple transcription ne suffit pas √† aider √† la r√©flexion. Il faut extraire du sens, structurer et synth√©tiser.
*   **D√©cision** : Cr√©er un processus ind√©pendant (**P4 - analyst_process**) qui "veille" sur le fichier JSONL et se d√©clenche p√©riodiquement (ou sur demande) pour mettre √† jour la synth√®se Markdown.
*   **Justification** :
    1.  **Non-bloquance** : L'analyse lourde (gros LLM) ne doit pas ralentir l'√©coute (P1) ou la r√©ponse (P2).
    2.  **Synth√®se Globale** : Contrairement au Cerveau qui ne voit que le "pr√©sent", l'Analyste a acc√®s √† tout l'historique de la session.
*   **Strat√©gie d'impl√©mentation** :
    *   **Le D√©clencheur** : L'analyste s'active toutes les X minutes ou apr√®s Y nouveaux segments.
    *   **Le Prompt de Valeur** : Il utilise un mod√®le puissant (ex: `Llama-3-8B` ou `Mistral`) avec une mission de "Secr√©taire de direction" : *"Voici les derni√®res r√©flexions. Organise-les par th√©matiques, souligne les contradictions, et propose 3 pistes d'approfondissement."*
    *   **Le Rendu** : Il √©crase `dashboard.md` avec une structure propre (Table des mati√®res, Checklists, Id√©es phares).
*   **Impact** : Transforme G√©rald d'un assistant "r√©actif" en un partenaire "proactif" qui pr√©pare le travail de r√©flexion sur ton deuxi√®me √©cran.

---

### üöÄ R√©sum√© de la Strat√©gie d'√âvolution (P1 √† P4)

1.  **P1 (Oreille)** : Capte et segmente l'audio (Silero VAD).
2.  **P2 (Cerveau)** : 
    *   Transcrit/Diarise (Whisper Docker).
    *   Route l'intention (Llama 1B).
    *   R√©pond si n√©cessaire (GPT-OSS).
    *   **Enregistre tout dans le JSONL.**
3.  **P3 (Bouche)** : Parle si P2 lui envoie du texte (Piper).
4.  **P4 (Analyste)** : Lit le JSONL en arri√®re-plan et **sculpte le Markdown** sur ton √©cran 2.

**Impact Global** : Tu peux parler pendant une heure. Ton √©cran 2 se remplit de notes structur√©es. Si tu poses une question, P2 te r√©pond √† l'oral. Si tu r√©fl√©chis tout seul, P2 se tait mais P4 organise tes propos.
